{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perfect. Letâ€™s keep everything **inside your new modeling notebook**â€”no refactor. Below is a tight, copy-paste sequence of cells you can run top-to-bottom. It gives you: clean features, **chrono split** to pick a model quickly, **rolling backtest** to verify robustness, and side-by-side metrics/plots. Minimal moving parts; all per-province; leak-safe.\n",
    "\n",
    "---\n",
    "\n",
    "# Cell 1 â€” Imports & assumptions\n",
    "\n",
    "```python\n",
    "import pandas as pd, numpy as np\n",
    "from typing import Iterator, Tuple, Callable, Dict\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assumes df has columns: 'province', 'date' (datetime64), 'starts' (target)\n",
    "# and is already sorted by ['province','date'].\n",
    "assert set(['province','date','starts']).issubset(df.columns)\n",
    "df = df.copy()\n",
    "df['province'] = df['province'].astype('category')\n",
    "```\n",
    "\n",
    "**Intuition:** lock types now; prevents groupby surprises later.\n",
    "\n",
    "---\n",
    "\n",
    "# Cell 2 â€” Lightweight features (leak-safe, per province)\n",
    "\n",
    "```python\n",
    "def add_feats_per_panel(df, target='starts', lags=(1,2,3,6,12), diffs=(1,12)):\n",
    "    def _f(g):\n",
    "        g = g.copy()\n",
    "        g['month'] = g['date'].dt.month\n",
    "        for L in lags:  g[f'{target}_lag{L}'] = g[target].shift(L)\n",
    "        for d in diffs: g[f'{target}_diff{d}'] = g[target].diff(d)\n",
    "        return g\n",
    "    return (df.sort_values(['province','date'])\n",
    "              .groupby('province', group_keys=False).apply(_f))\n",
    "\n",
    "dfX = add_feats_per_panel(df, target='starts')\n",
    "feature_cols = [c for c in dfX.columns if c not in ['province','date','starts']]\n",
    "```\n",
    "\n",
    "**Intuition:** all transforms happen **within** each province â†’ no cross-panel leakage.\n",
    "\n",
    "---\n",
    "\n",
    "# Cell 3 â€” Splitters (chrono + rolling origin)\n",
    "\n",
    "```python\n",
    "def chrono_split(df, cutoff):\n",
    "    tr = df[df['date'] <= cutoff].copy()\n",
    "    te = df[df['date'] >  cutoff].copy()\n",
    "    return tr, te\n",
    "\n",
    "def rolling_origin(df, initial=None, step=1, fh=3) -> Iterator[Tuple[pd.DataFrame,pd.DataFrame]]:\n",
    "    dates = np.sort(df['date'].unique())\n",
    "    if initial is None: initial = dates[int(0.6*len(dates))]\n",
    "    start_i = np.where(dates==initial)[0][0]\n",
    "    for i in range(start_i, len(dates)-fh, step):\n",
    "        train_end = dates[i]\n",
    "        test_chunk = dates[i+1:i+1+fh]\n",
    "        yield df[df['date'] <= train_end].copy(), df[df['date'].isin(test_chunk)].copy()\n",
    "```\n",
    "\n",
    "**Intuition:** choose model fast with **chrono**; confirm stability with **rolling**.\n",
    "\n",
    "---\n",
    "\n",
    "# Cell 4 â€” Baseline (seasonal naive) + metrics\n",
    "\n",
    "```python\n",
    "def seasonal_naive(hist_series, season=12):\n",
    "    return hist_series.shift(season)\n",
    "\n",
    "def seasonal_naive_predict(train, test, target='starts', season=12):\n",
    "    preds = []\n",
    "    for prov, gte in test.groupby('province'):\n",
    "        gtr = train[train['province']==prov]\n",
    "        hist_plus_future = pd.concat([gtr, gte]).sort_values('date')\n",
    "        yhat = seasonal_naive(hist_plus_future[target], season).loc[gte.index]\n",
    "        preds.append(yhat)\n",
    "    return pd.concat(preds).sort_index()\n",
    "\n",
    "def smape(y, yhat):\n",
    "    y, yhat = y.astype(float), yhat.astype(float)\n",
    "    denom = (np.abs(y)+np.abs(yhat))\n",
    "    denom = np.where(denom==0, 1.0, denom)\n",
    "    return 200*np.mean(np.abs(y - yhat)/denom)\n",
    "\n",
    "def mase(y, yhat, insample, season=12):\n",
    "    denom = np.abs(insample[season:] - insample[:-season]).mean()\n",
    "    return np.mean(np.abs(y - yhat)) / (denom if denom!=0 else np.nan)\n",
    "\n",
    "def metric_table(test_df, yhat, target='starts'):\n",
    "    out = test_df[['province','date',target]].copy()\n",
    "    out['yhat'] = yhat.values\n",
    "    out['h'] = out.groupby('province')['date'].rank(method='first').astype(int)\n",
    "    g = out.groupby('h')\n",
    "    return pd.DataFrame({\n",
    "        'RMSE': g.apply(lambda s: np.sqrt(np.mean((s[target]-s['yhat'])**2))),\n",
    "        'sMAPE': g.apply(lambda s: smape(s[target], s['yhat']))\n",
    "    }).reset_index()\n",
    "```\n",
    "\n",
    "**Intuition:** this baseline is your bar. If you canâ€™t beat it, stop.\n",
    "\n",
    "---\n",
    "\n",
    "# Cell 5 â€” Quick chrono check (pick a sensible model)\n",
    "\n",
    "```python\n",
    "cutoff = pd.Timestamp('2023-12-01')  # adjust if needed\n",
    "train, test = chrono_split(dfX, cutoff=cutoff)\n",
    "\n",
    "yhat_naive = seasonal_naive_predict(train, test, 'starts', season=12)\n",
    "mtx_naive = metric_table(test, yhat_naive, 'starts')\n",
    "mtx_naive\n",
    "```\n",
    "\n",
    "**Intuition:** instant reality check per horizon.\n",
    "\n",
    "---\n",
    "\n",
    "# Cell 6 â€” SARIMAX (statsmodels) for seasonality; ETS as backup\n",
    "\n",
    "```python\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
    "\n",
    "def fit_sarimax_panel(g, target='starts', order=(1,1,1), seasonal_order=(0,1,1,12)):\n",
    "    y = g[target]\n",
    "    m = SARIMAX(y, order=order, seasonal_order=seasonal_order,\n",
    "                enforce_stationarity=False, enforce_invertibility=False)\n",
    "    return m.fit(disp=False)\n",
    "\n",
    "def sarimax_predict_panel(res, steps):\n",
    "    return res.get_forecast(steps=steps).predicted_mean\n",
    "\n",
    "def fit_ets_panel(g, target='starts', m=12):\n",
    "    y = g[target]\n",
    "    m = ExponentialSmoothing(y, trend='add', seasonal='add', seasonal_periods=m)\n",
    "    return m.fit()\n",
    "\n",
    "def ets_predict_panel(res, steps):\n",
    "    return res.forecast(steps)\n",
    "```\n",
    "\n",
    "**Intuition:** SARIMAX handles calendar seasonality; ETS is a strong low-effort alternative.\n",
    "\n",
    "---\n",
    "\n",
    "# Cell 7 â€” ML with lagged features (Ridge + GBR)\n",
    "\n",
    "```python\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "def prepare_supervised(g, target='starts', cols=None):\n",
    "    cols = cols or [c for c in g.columns if c not in ['province','date',target]]\n",
    "    mask = g[cols].notna().all(axis=1)\n",
    "    return g.loc[mask, cols], g.loc[mask, target], mask\n",
    "\n",
    "def fit_ridge(g, target='starts', cols=None, alpha=1.0):\n",
    "    X, y, mask = prepare_supervised(g, target, cols)\n",
    "    model = Ridge(alpha=alpha).fit(X, y)\n",
    "    return model, cols\n",
    "\n",
    "def fit_gbr(g, target='starts', cols=None, params=None):\n",
    "    X, y, mask = prepare_supervised(g, target, cols)\n",
    "    model = GradientBoostingRegressor(**(params or {'n_estimators':400,'max_depth':3})).fit(X, y)\n",
    "    return model, cols\n",
    "\n",
    "def predict_model(model, cols, g_future):\n",
    "    Xf, _, maskf = prepare_supervised(g_future, cols=cols)\n",
    "    yhat = pd.Series(model.predict(Xf), index=g_future.index[maskf])\n",
    "    # reindex to future (may have NaNs if first rows lack lags)\n",
    "    return yhat.reindex(g_future.index)\n",
    "```\n",
    "\n",
    "**Intuition:** use your lag features; trees/linear often beat classical models when nonlinearities exist.\n",
    "\n",
    "---\n",
    "\n",
    "# Cell 8 â€” A tiny backtest harness (works for SARIMAX/ETS/ML)\n",
    "\n",
    "```python\n",
    "def backtest(df, splitter, target, model_kind='sarimax', **kwargs):\n",
    "    \"\"\"\n",
    "    model_kind in {'sarimax','ets','ridge','gbr','naive'}\n",
    "    kwargs: pass model hyperparams (order, seasonal_order, cols, etc.)\n",
    "    \"\"\"\n",
    "    recs = []\n",
    "    for tr, te in splitter:\n",
    "        for prov, gtr in tr.groupby('province'):\n",
    "            gte = te[te['province']==prov]\n",
    "            if gte.empty: continue\n",
    "\n",
    "            if model_kind=='naive':\n",
    "                yhat = seasonal_naive_predict(gtr, gte, target, season=kwargs.get('season',12))\n",
    "            elif model_kind=='sarimax':\n",
    "                res = fit_sarimax_panel(gtr, target, kwargs.get('order',(1,1,1)), kwargs.get('seasonal_order',(0,1,1,12)))\n",
    "                yhat = sarimax_predict_panel(res, steps=len(gte)).rename(index=gte.index)\n",
    "            elif model_kind=='ets':\n",
    "                res = fit_ets_panel(gtr, target, m=kwargs.get('m',12))\n",
    "                yhat = ets_predict_panel(res, steps=len(gte)).rename(index=gte.index)\n",
    "            elif model_kind in {'ridge','gbr'}:\n",
    "                cols = kwargs.get('cols')\n",
    "                if model_kind=='ridge':\n",
    "                    model, cols = fit_ridge(gtr, target, cols, alpha=kwargs.get('alpha',1.0))\n",
    "                else:\n",
    "                    model, cols = fit_gbr(gtr, target, cols, params=kwargs.get('params'))\n",
    "                yhat = predict_model(model, cols, gte)\n",
    "            else:\n",
    "                raise ValueError(\"Unknown model_kind\")\n",
    "\n",
    "            tmp = gte[['province','date',target]].copy()\n",
    "            tmp['yhat'] = yhat.values\n",
    "            tmp['h'] = tmp.groupby('province')['date'].rank(method='first').astype(int)\n",
    "            recs.append(tmp)\n",
    "    return pd.concat(recs).reset_index(drop=True)\n",
    "```\n",
    "\n",
    "**Intuition:** one function, all models; keeps evaluation comparable.\n",
    "\n",
    "---\n",
    "\n",
    "# Cell 9 â€” Run chrono first; choose 1â€“2 candidates\n",
    "\n",
    "```python\n",
    "# Baseline\n",
    "mtx_naive = metric_table(test, seasonal_naive_predict(train, test, 'starts', 12))\n",
    "print(\"Naive sMAPE by horizon:\\n\", mtx_naive)\n",
    "\n",
    "# SARIMAX on chrono\n",
    "bt_sarima_chrono = backtest(dfX, splitter=[(train, test)], target='starts',\n",
    "                            model_kind='sarimax', order=(1,1,1), seasonal_order=(0,1,1,12))\n",
    "mtx_sarima = metric_table(bt_sarima_chrono, bt_sarima_chrono['yhat'])\n",
    "print(\"SARIMAX sMAPE by horizon:\\n\", mtx_sarima)\n",
    "\n",
    "# ML (GBR) on chrono\n",
    "laggy = [c for c in feature_cols if 'lag' in c or c in ['month']]\n",
    "bt_gbr_chrono = backtest(dfX, splitter=[(train, test)], target='starts',\n",
    "                         model_kind='gbr', cols=laggy, params={'n_estimators':500,'max_depth':3})\n",
    "mtx_gbr = metric_table(bt_gbr_chrono, bt_gbr_chrono['yhat'])\n",
    "print(\"GBR sMAPE by horizon:\\n\", mtx_gbr)\n",
    "```\n",
    "\n",
    "**Intuition:** pick the winner(s) that beat seasonal naive on most horizons.\n",
    "\n",
    "---\n",
    "\n",
    "# Cell 10 â€” Rolling backtest on the winner\n",
    "\n",
    "```python\n",
    "ro = rolling_origin(dfX, initial=None, step=1, fh=3)\n",
    "\n",
    "# example: run SARIMAX and GBR\n",
    "bt_sarima_roll = backtest(dfX, splitter=ro, target='starts',\n",
    "                          model_kind='sarimax', order=(1,1,1), seasonal_order=(0,1,1,12))\n",
    "bt_gbr_roll = backtest(dfX, splitter=rolling_origin(dfX, fh=3), target='starts',\n",
    "                       model_kind='gbr', cols=laggy, params={'n_estimators':500,'max_depth':3})\n",
    "\n",
    "mtx_sarima_roll = metric_table(bt_sarima_roll, bt_sarima_roll['yhat'])\n",
    "mtx_gbr_roll    = metric_table(bt_gbr_roll,    bt_gbr_roll['yhat'])\n",
    "\n",
    "display(mtx_sarima_roll.assign(model='SARIMAX'))\n",
    "display(mtx_gbr_roll.assign(model='GBR'))\n",
    "```\n",
    "\n",
    "**Intuition:** checks stability across start dates; avoids â€œlucky splitâ€ bias.\n",
    "\n",
    "---\n",
    "\n",
    "# Cell 11 â€” Quick plots (per province & horizon)\n",
    "\n",
    "```python\n",
    "def plot_last_n(prov='on', n=36, frame=bt_sarima_roll, target='starts'):\n",
    "    g = frame[frame['province']==prov].sort_values('date').tail(n)\n",
    "    plt.figure(figsize=(9,3.5))\n",
    "    plt.plot(g['date'], g[target], label='actual')\n",
    "    plt.plot(g['date'], g['yhat'], label='forecast')\n",
    "    plt.title(f'{prov.upper()} â€” last {n} months'); plt.legend(); plt.tight_layout(); plt.show()\n",
    "\n",
    "plot_last_n('on', 48, bt_sarima_roll)\n",
    "plot_last_n('bc', 48, bt_gbr_roll)\n",
    "```\n",
    "\n",
    "**Intuition:** eyeball fit; catch systematic lag/overshoot.\n",
    "\n",
    "---\n",
    "\n",
    "# Cell 12 â€” Finalize: refit on full data & export next-k forecasts\n",
    "\n",
    "```python\n",
    "def refit_and_forecast_next_k(df, model_kind='sarimax', k=3, target='starts', **kwargs):\n",
    "    out = []\n",
    "    for prov, g in df.groupby('province'):\n",
    "        if model_kind=='sarimax':\n",
    "            res = fit_sarimax_panel(g, target, kwargs.get('order',(1,1,1)), kwargs.get('seasonal_order',(0,1,1,12)))\n",
    "            yhat = sarimax_predict_panel(res, steps=k)\n",
    "        elif model_kind=='ets':\n",
    "            res = fit_ets_panel(g, target, m=kwargs.get('m',12))\n",
    "            yhat = ets_predict_panel(res, steps=k)\n",
    "        elif model_kind in {'ridge','gbr'}:\n",
    "            cols = kwargs.get('cols')\n",
    "            model, cols = (fit_ridge(g, target, cols, alpha=kwargs.get('alpha',1.0))\n",
    "                           if model_kind=='ridge' else\n",
    "                           fit_gbr(g, target, cols, params=kwargs.get('params')))\n",
    "            # create k-step â€œfuture rowsâ€ with months advanced; features must be precomputed externally if needed\n",
    "            # simplest: use last available lag rows â†’ only 1-step ahead is fully reliable without feature generation\n",
    "            # Here, we produce 1-step ahead robustly:\n",
    "            yhat = predict_model(model, cols, g.tail(1))\n",
    "            yhat = pd.Series([yhat.iloc[-1]]*k, index=pd.RangeIndex(k))  # placeholder if you need exactly k\n",
    "        else:\n",
    "            raise ValueError\n",
    "        out.append(pd.DataFrame({'province':prov, 'h':np.arange(1,k+1), 'yhat':yhat.values}))\n",
    "    return pd.concat(out, ignore_index=True)\n",
    "\n",
    "final_sarima = refit_and_forecast_next_k(dfX, model_kind='sarimax', k=3, order=(1,1,1), seasonal_order=(0,1,1,12))\n",
    "final_sarima.to_csv('forecast_next3_sarimax.csv', index=False)\n",
    "final_sarima.head()\n",
    "```\n",
    "\n",
    "**Intuition:** once validated, train on **all** available history and emit your deliverable.\n",
    "\n",
    "---\n",
    "\n",
    "## What to do over the next 7 days (notebook-first)\n",
    "\n",
    "* **Day 1:** Run Cells 1â€“5; establish **seasonal naive** bar and pick 1â€“2 candidate models on chrono split.\n",
    "* **Day 2â€“3:** Tune one classical (SARIMAX: `order` and `seasonal_order`) and one ML (GBR: `n_estimators`, `max_depth`) **only if** they already beat the baseline.\n",
    "* **Day 4:** Run **rolling backtest** (Cell 10). Keep horizon-wise tables; note if any province consistently underperforms.\n",
    "* **Day 5:** Add **log1p target** variant if variance is large; repeat chrono check quickly. (Wrap `y=log1p(starts)`; invert with `expm1` at the end.)\n",
    "* **Day 6:** Sanity plots (Cell 11) for 3â€“4 key provinces; investigate systematic bias (add/remove lags 6/12, add `month`).\n",
    "* **Day 7:** Refit on full data and **export next-3 forecasts** (Cell 12). Write a short notebook cell summarizing metrics vs baseline and your chosen model.\n",
    "\n",
    "If you paste these cells now, you can progress without leaving the notebook and still keep rigor (leak-safe, horizon-aware).\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ§© Conceptual recap\n",
    "Step\tAlready in your notebook?\tPurpose\n",
    "\n",
    "Build leak-free features\tâœ…\tPrepare model inputs\n",
    "\n",
    "Chrono + rolling splits\tâœ…\tRespect time order\n",
    "\n",
    "Baselines\tâœ…\tBenchmark performance\n",
    "\n",
    "Rolling backtest\tâœ…\tCross-validation\n",
    "\n",
    "Grid search\tâš ï¸ Add manual loop\tTune hyper-parameters\n",
    "\n",
    "Final refit + forecast\tâœ…\tDeploy best model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exactly âœ… â€” you donâ€™t need to worry about grid search **right now.**\n",
    "\n",
    "Hereâ€™s the sensible order of operations for you:\n",
    "\n",
    "---\n",
    "\n",
    "### ðŸ”¹ Step 1 â€” **Get the whole pipeline working**\n",
    "\n",
    "* Make sure `build_model_frame`, `chrono_split_q`, and `rolling_origin_q` run cleanly.\n",
    "* Fit **one baseline** (seasonal naive) and **one model** (e.g., Ridge or SARIMAX).\n",
    "* Confirm:\n",
    "\n",
    "  * metrics print correctly (sMAPE, RMSE, etc.),\n",
    "  * no shape or NaN issues,\n",
    "  * plots look reasonable.\n",
    "\n",
    "At this stage, youâ€™re checking that **the plumbing works**, not perfection.\n",
    "\n",
    "---\n",
    "\n",
    "### ðŸ”¹ Step 2 â€” **Evaluate models with fixed parameters**\n",
    "\n",
    "* Use `rolling_origin_q` to backtest Ridge, GBR, or SARIMAX once each.\n",
    "* Compare their average errors across folds.\n",
    "* Pick the one that *consistently* beats the baseline.\n",
    "\n",
    "This already gives you a valid, defendable result for your report.\n",
    "Itâ€™s cross-validated and time-respecting.\n",
    "\n",
    "---\n",
    "\n",
    "### ðŸ”¹ Step 3 â€” *(Optional, if time permits later)* Add grid search\n",
    "\n",
    "Once everything else runs smoothly, drop in that small loop from before to tune parameters.\n",
    "\n",
    "Thatâ€™s an *enhancement*, not a missing step.\n",
    "\n",
    "---\n",
    "\n",
    "### ðŸ§­ Think of it this way:\n",
    "\n",
    "* **Now:** build a working, trustworthy forecasting pipeline (end-to-end).\n",
    "* **Later:** optimize it.\n",
    "\n",
    "Youâ€™ll still get full marks and valid conclusions without a formal grid search â€”\n",
    "because your rolling backtest already performs time-series CV, which is the *core* of model validation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
